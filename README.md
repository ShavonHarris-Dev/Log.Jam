# ğŸ¤– AI Console Log Analyzer

**One click log analysis devs love** - Upload your console logs and get instant AI-powered insights to debug 80% faster.

![AI Console Log Analyzer](https://img.shields.io/badge/React-18+-blue.svg) ![OpenAI](https://img.shields.io/badge/OpenAI-GPT--3.5--turbo-green.svg) ![TypeScript](https://img.shields.io/badge/TypeScript-5+-blue.svg)

## âœ¨ Features

- **ğŸ¯ AI-Powered Analysis** - GPT-3.5-turbo identifies critical issues and provides actionable fixes
- **ğŸ“ Multiple Input Methods** - Drag & drop files, paste logs, or try sample logs
- **ğŸ¨ Modern Dark UI** - Beautiful, accessible interface with excellent contrast
- **âš¡ Smart Log Processing** - Automatically cleans and parses different log formats
- **ğŸ“‹ Easy Export** - Copy results as Markdown or plain text
- **ğŸš€ Instant Results** - Fast analysis with confidence scoring

## ğŸš€ Quick Start

### 1. Clone & Install
```bash
git clone <your-repo>
cd logSense
npm install
```

### 2. Set Up OpenAI API
```bash
# Copy the example environment file
cp .env.example .env.local

# Add your OpenAI API key to .env.local
VITE_OPENAI_API_KEY=sk-your-api-key-here
```

### 3. Run Development Server
```bash
npm run dev
```

Visit `http://localhost:5173` and start analyzing logs! ğŸ‰

## ğŸ”§ Configuration

### Environment Variables
Create a `.env.local` file with:

```env
# Required: Your OpenAI API key
VITE_OPENAI_API_KEY=sk-your-api-key-here

# Optional: Custom model (defaults to gpt-3.5-turbo)
VITE_OPENAI_MODEL=gpt-3.5-turbo

# Optional: Custom API base URL (for Azure OpenAI, etc.)
VITE_OPENAI_BASE_URL=https://your-custom-endpoint.com/v1
```

### Getting an OpenAI API Key
1. Go to [OpenAI Platform](https://platform.openai.com/)
2. Sign up/login and go to API Keys
3. Create a new secret key
4. Add it to your `.env.local` file

## ğŸ¯ Usage

### Try Sample Logs
Click any sample button to test the analyzer:
- **React Errors** - TypeError and component issues
- **Network Issues** - CORS and API failures  
- **JS Runtime Errors** - ReferenceError, SyntaxError, etc.

### Upload Your Own Logs
- **Drag & Drop** - Drop .log or .txt files
- **Paste Content** - Copy console output directly
- **File Upload** - Click to browse files

### Analyze Results
- **Critical Issues** - Top 3-5 problems with explanations
- **Confidence Scores** - AI certainty rating (0-100%)
- **Fix Suggestions** - Actionable debugging steps
- **Export Options** - Copy as Markdown or text

## ğŸ—ï¸ Architecture

```
src/
â”œâ”€â”€ components/          # React components
â”‚   â”œâ”€â”€ FileUpload.tsx  # Upload interface
â”‚   â””â”€â”€ LogAnalysis.tsx # Results display
â”œâ”€â”€ services/           # Core logic
â”‚   â”œâ”€â”€ aiAnalyzer.ts   # OpenAI integration
â”‚   â””â”€â”€ logProcessor.ts # Log parsing
â”œâ”€â”€ data/              # Sample data
â”‚   â””â”€â”€ sampleLogs.ts  # Example console logs
â””â”€â”€ types.ts           # TypeScript definitions
```

## ğŸ”¬ How It Works

1. **Log Processing** - Cleans timestamps, extracts errors, identifies patterns
2. **AI Analysis** - Sends processed logs to GPT-3.5-turbo with specialized prompts
3. **Smart Fallback** - Uses rule-based detection if AI fails
4. **Result Formatting** - Validates and formats AI response for consistency

## ğŸš€ Deployment

### Vercel (Recommended)
```bash
npm run build
# Deploy via Vercel dashboard or CLI
```

### Netlify
```bash
npm run build
# Drag dist/ folder to Netlify or use CLI
```

**Important:** Add your `VITE_OPENAI_API_KEY` to your deployment platform's environment variables.

## ğŸ¨ Browser Support

- âœ… Chrome 90+
- âœ… Firefox 88+  
- âœ… Safari 14+
- âœ… Edge 90+

## ğŸ”’ Security Notes

- API keys are stored in environment variables
- OpenAI calls made client-side (consider backend API for production)
- No log data stored permanently
- CORS configured for browser compatibility

## ğŸ“Š Performance

- **Log Processing** - Handles logs up to 10k lines
- **AI Analysis** - ~2-5 seconds average response time
- **Bundle Size** - ~500KB gzipped
- **Memory Usage** - ~50MB typical

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

MIT License - see LICENSE file for details.

## ğŸ™ Acknowledgments

- [OpenAI](https://openai.com/) for GPT-3.5-turbo
- [Vite](https://vitejs.dev/) for blazing fast development
- [React](https://reactjs.org/) for the UI framework

---

**Made with â¤ï¸ for developers who spend too much time debugging console logs** ğŸ›â¡ï¸âœ¨